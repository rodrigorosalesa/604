---
title: "Final Project: Public Safety Measures and Public Health for Covid-19"
author: "Paul Croome(), Rodrigo Rosales Alvarez(), Ann Siddiqui() and Kane Smith (30179486)"
date: "2022-12-14"
output: 
  pdf_document: 
    toc_depth: 4
subtitle: "Data 603 - Statistical Modelling with Data"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\begin{center}\textbf{} 
\\Professor: Dr. Paul Galpern
\\University of Calgary
\\Calgary, Alberta
\end{center}



\newpage
\tableofcontents



\newpage
# Introduction
The domain of our project covers healthcare-related indicators of the wellbeing of countries during the coronavirus disease 2019 (COVID-19) pandemic. In particular, we will be examining data related to the prevalence and severity of the COVID-19 pandemic and the governmental and societal measures taken to reduce the spread of the disease. These data were all daily reported between January 2020 and October 2022.

This is an interesting and important topic of study because, in our increasingly interconnected world, contagious diseases can be transmitted over vast distances remarkably easily. Even small, remote outbreaks of diseases anywhere in the world can swiftly turn into a global pandemic, which can then cause devastation on personal, societal, and worldwide scales. 


## Research Questions
1) What population-related metrics of countries around the world are most strongly related to the prevalence and severity of COVID-19 experienced in a country between February 2020 and October 2022 (as measured by average daily COVID-19 cases and deaths)? 

    a) What is the best model that can be built from these data for predicting the average daily new COVID-19 cases experienced in a country? 
    
    b) What is the best model that can be built from these data for predicting the average daily new COVID-19 deaths experienced in a country?

2) Among countries with reliably reported data relating to cases, positive test rates, vaccinations, and boosters, what societal and governmental responses to the COVID-19 pandemic are most strongly related to the prevalence and severity of COVID-19 experienced in a country between February 2020 and October 2022 (as measured by average daily COVID-19 cases and deaths)?

    a) What is the best model that can be built from these daily-reported data for predicting the daily new COVID-19 cases in a country?
    
    b) What is the best model that can be built from these daily-reported data for predicting the daily new COVID-19 deaths in a country?



\newpage
# Data Set Definition
The dataset we will use consists of diverse information related to the COVID-19 pandemic, including a country’s daily rates of COVID-19 diagnoses, hospitalizations, deaths, vaccinations, and booster shots. We will use features of these data to determine the prevalence and severity of the COVID-19 pandemic for each country . The dataset consists of daily information from January 1, 2020 to October 26, 2022 for more than 220 countries; each row corresponds to the Covid-19 information reported by an specific country in a certain date.

This dataset is in tabular form contained in a CSV file and is licensed for open access under the Creative Commons BY license. The dataset was put together by [Our World in Data](https://ourworldindata.org/coronavirus); more importantly, the data set is being updated daily by the same organization, for more information about the data pipeline and how the data set is being maintained click [here](https://docs.owid.io/projects/covid/en/latest/data-pipeline.html#overview).  



\newpage
# Methodology

To answer the questions outlined in our introduction, we will be creating various multiple linear regression models. Our analysis will follow the below structure:

**Preparation**
-Libraries Import
-Data Import
-Data Cleaning 
-Variable Definition 
-Data Preparation 

**Analysis**
- Question 1 Multiple Linear Regression Models
  - New Cases Model
    - New Cases Assumptions 
    - New Cases Box-Cox Transformation
    - Box-Cox Transformed Model Assumptions
  - New Deaths Model
    - New Deaths Assumptions
    - New Deaths Box-Cox Transformation 
- Question 2 Multiple Linear Regression Models
  - Model 1
    - Model 1 Assumptions 
    - Model 1 Box-Cox Transformation
    - Box-Cox Transformed Model Assumptions 
  - Model 2
    - Model 2 Assumptions
    - Model 2 Box-Cox Transformation
    - Box-Cox Transformed Model Assumptions 

**Results** 
-Question 1
  - New Cases Model
  - New Deaths Model
-Question 2
  - Model 1
  - Model 2

**Discussion** 
-Question 1
-Question 2

The above tasks were divided among the team in the following way: The preparation, including importing libraries, importing the data, cleaning the data, defining variables to be used in analysis, and wrangling the data, was all distributed evenly among the four team members. Analysis of Question 1 was divided between Rodrigo and Kane; this includes building the MLR models, checking the assumptions, doing any transformations and interpreting the results. Analysis of Question 2 was divided between Paul and Ann which also included building the MLR models, checking the assumptions, doing any transformations and interpreting the results.

# Preparation 
## Libraries 
```{r, results='hide', echo=FALSE, include=FALSE}
library(dplyr) # data manipulation
library(ggplot2) # graphs
library(GGally) # extension to ggplot2
library(mosaic) # statistics and calculus functions
library(tidyverse) # data science 
library(tidyr) # tidy data
library(olsrr) # teaching and learning OLS regression
library(leaps) # best subset of variables for a model
library(mctest) # VIF
library(car) # VIF
library(lmtest) # Bracuh-Pagan
library(agricolae) # Newman-Keuls
library(MASS) # box-cox
options(scipen=999) # show results without scientific notation
```


## Data Import
As our data is in CSV format, we simple use the function **read_csv()** to import our file into a data frame.
```{r}
covid_raw <- read_csv('data.csv', show_col_types = FALSE)
```


## Data Cleaning 
Many countries and facilities are under reporting Covid-19 statistics like cases and deaths, according to Claire Klobucista from Council of Foreign Relations. This is could be catastrophically as government could not respond accordingly to the real situation. For our research this is very important as well, if we put bad data into our model, we would create a bad model. To solve this problem we will remove from our dataset the countries that are present in the bottom 5% of number of new cases smoothed per million and number of new deaths smoothed per million. 

```{r}
# Removing locations from the data set that are aggregates of countries
not_countries <- c("Europe", "European Union", "High Income", "International", "Africa", "Asia", "Low Income", "Lower Middle Income", "North America", "Oceania", "South America", "Upper Middle Income", "World")
covid_raw <- covid_raw[!covid_raw$location %in% not_countries, ]

# Removing countries with 0 covid cases or deaths 
zero_country_deaths <- covid_raw[covid_raw$new_deaths_smoothed_per_million == 0 ,]
zero_country_cases <- covid_raw[covid_raw$new_cases_smoothed_per_million ==0 ,]
zero_country_cases_list <- unique(zero_country_cases$location)
zero_country_deaths_list <- unique(zero_country_deaths$location)
zero_country_case_deaths <- append(zero_country_cases_list, zero_country_deaths_list)
covid_raw <- covid_raw[!covid_raw$location %in% zero_country_case_deaths, ]

# Getting countries with bottom 5% of new_cases_smoothed_per_million
tenth_percentile_cases <- quantile(covid_raw$new_cases_smoothed_per_million, probs = 0.05, na.rm = TRUE)
bad_country_cases <- covid_raw[covid_raw$new_cases_smoothed_per_million < tenth_percentile_cases,]
bad_country_list_cases <- unique(bad_country_cases$location)

# Getting countries with bottom 5% of new_deaths_smoothed_per_million
tenth_percentile_deaths <- quantile(covid_raw$new_deaths_smoothed_per_million, probs = 0.05, na.rm = TRUE)
bad_country_deaths <- covid_raw[covid_raw$new_deaths_smoothed_per_million < tenth_percentile_deaths,]
bad_country_list_deaths <- unique(bad_country_deaths$location)

# Remove countries that appear in either above lists
bad_country_list <- append(bad_country_list_deaths, bad_country_list_cases)
good_countries <-   covid_raw[!covid_raw$location %in% bad_country_list, ]
covid_data <- good_countries
```

More cleaning tasks were missing, for starters we generated a new column called *smokers* that was the average of *female_smokers* and *male_smokers*, after that we replaced all the null values for 0s, as we can´t assign a number to a factor, we decided to drop continent and iso_code, columns, test_unitsand date as are not important for our analysis.
```{r}
# Creating the column "smokers"
covid_data$smokers <- (covid_data[['male_smokers']] + covid_data[['female_smokers']]) / 2

# Drop column continent
covid = subset(covid_data, select = -c(iso_code, continent, tests_units, date) )

# Changing Null Values to 0s
covid[is.na(covid)] = 0
```


## Variable Definition.

**Independent Variable** 

- _new_cases_: new confirmed cases of COVID-19. Continuous Variable.
- _new_deaths_: new deaths attributed to COVID-19. Continuous Variable.


**Dependent Variables**

1) Population metrics

    - _extreme_poverty_: The number of the population per million that is considered to be in extreme poverty.
    - _gdp_per_capita_: GDP per capita of the country.
    - _median_age_: Median age of the population.
    - _population_: Number of people in the country.
    - _human_development_index_: Human development index as calculated by [Human Development Reports](https://hdr.undp.org/data-center/human-development-index#/indicies/HDI).
    - _population_density_: Population density of the country.
    - _aged_65_older_: The number of the population per million that is aged over 65 years old.
    

2) Health metrics

    - _cardiovasc_death_rate_: The death rate caused by cardiovascular disease.
    - _diabetes_prevalence_: The number of the population per million that is diagnosed with diabetes.
    - _life_expectancy_: The life expectancy of the population of a country.
    - _reproduction_rate_: The rate of reproduction of the population of a country.
    - _smokers_: The number of the population per million that smokes cigarettes.
    

3) COVID metrics

    - _stringency_index_: A measure of how stringent the policies related to controlling the spread of COVID is.
    - _hosp_patients_: The number of people hospitalized due to COVID.
    - _new_tests_: The number of new COVID tests conducted in a day.


## Data Preparation 
To create the final dataset that will be used to create the *New Cases Model* and *New Deaths Model* we performed an aggregation function (mean) across the variable country as we are only interested in having one data point per country. The new data point will be the mean of every other variable present in the table; we decided to use the mean as that is the best way to aggregate the variables that we are interested on using like new cases, new deaths, population, stringency index and more.
```{r}
covid_agg <- covid %>% group_by(location) %>% summarise(across(everything(), mean), .groups = 'drop') %>% as.data.frame()
```

#Analysis

## Multiple Linear Regression Models for Research Question 1
Our research question number 1 is:

1) What population-related metrics of countries around the world are most strongly related to the prevalence and severity of COVID-19 experienced in a country between February 2020 and October 2022 (as measured by average daily COVID-19 cases and deaths)? 

    a) What is the best model that can be built from these data for predicting the average daily new COVID-19 cases experienced in a country? 
    
    b) What is the best model that can be built from these data for predicting the average daily new COVID-19 deaths experienced in a country?
    
For this reason we are going to build two Multiple Linear Regressions Models, one for New Cases and one for New Deaths, using the tools we learnt during class.

It is important to state that for all the statistical tests that we will perform trhoughout this project we will use a value of $\alpha = 0.05$.

### New Cases Model

We started by defining our full model, including all the variables that make senses to predict New Covid-19 Cases for a specific country. Using the summary() function we are able to see the most important information about our model. 

```{r}
model_cases_full = lm(new_cases ~ aged_65_older + smokers + cardiovasc_death_rate + diabetes_prevalence + extreme_poverty + gdp_per_capita + median_age + life_expectancy + population + stringency_index + human_development_index + reproduction_rate + hosp_patients + new_tests + population_density, data=covid_agg)

summary(model_cases_full)
```

Using the *Step Wise Regression Procedure* to create the best fit additive model we found out that only 3 variables were significant; for these 3 terms we can reject reject the Null Hypothesis for the individual coefficient t test, meaning that the terms are significant and the coefficients should be different than 0. The 3 terms that passed the mentioned test are: **population**, **hosp_patients**, **life expectancy**.

Hypothesis Testing for Individual Coefficient t tests.\
$H_0: \beta_i = 0$\
$H_a: \beta_i \neq 0$\
$(i = \text{population, hosp_patients, life_expectancy})$

```{r}
model_cases_stepwise = ols_step_both_p(model_cases_full, pent=0.1, prem=0.3, progress=TRUE)
```

The model obtained after performing the *Step Wise Regression Procedure* is:\
$\widehat{y}_{new.cases} = -508.038 + 0.022600844 x_{new_tests} + 0.000076064 x_{population} -0.404601984 x_{hosp.patients} + 103.552 x_{aged.65.older}$

Adjusted R Squared of our model is: 0.8692, meaning that the proportion of the total variation that is explained by the model is 86.92%.

```{r}
model_cases_revised = lm(new_cases ~ new_tests + population + hosp_patients + aged_65_older, data=covid_agg)
summary(model_cases_revised)
```

Global F-test:

Null hypothesis: $H_{0}: \beta_{population}=\beta_{hosp_patients}=\beta_{life_expectancy}=0$

Alternative hypothesis: At least one $\beta_{i} (i= population, hosp_patients, life_expectancy)$ does not equal 0.

We will set the alpha value to 0.05.
```{r}
model_cases_null <- lm(new_cases~1,data=covid_agg)
anova(model_cases_null,model_cases_revised)
```

From the output of our global F-test, we get a p-value of 0.000005709  which is less than our alpha value of 0.05 so we can reject our null hypothesis that all of our regression coefficients are equal to 0 and can conclude with a significance level of 0.05 that our model has at least one significant predictor.


Using interactions terms can be a powerful way to increase the efficiency of our model as sometimes the effect of an independent variable on a dependent variable, in our case new Covid-19 cases, is not constant over all of the values of the other independent variables. As population is on our terms we decided to include interactions terms as depending on the total population of a country all the other variables could change.

Hypothesis Testing for Individual Coefficient t tests.\
$H_0: \beta_i = 0$\
$H_a: \beta_i \neq 0$\
$(i = \text{(population, hosp_patients, aged_65_older, new_tests)^2})$

We failed to reject our Null Hypothesis for the interaction terms, suggesting they should not be including in our model.

```{r}
model_cases_interactions = lm(new_cases ~ (population + hosp_patients + aged_65_older +new_tests)^2, data=covid_agg)
summary(model_cases_interactions)
```


We would like to try a higher order term to see if we can improve our Adjusted R Squared, as some of the relations with the dependent variable could be curvature instead of linear. To check this relations we will use the ggpairs to plot the correlation between the independent variables and the dependent variables. 

```{r}
covid_higher_order <-data.frame(covid_agg$new_cases, covid_agg$population, covid_agg$hosp_patients, covid_agg$aged_65_older, covid_agg$new_tests)

ggpairs(covid_higher_order, lower = list(continuous="smooth_loess", combo="facethist", discrete="facetbar", na="na"))
```

Right away we can observe that there is a curvature relationship between new_tests and new_cases, for that reason we decided to try a square term to see if the model behaves better. 

Hypothesis Testing for Individual Coefficient t tests.\
$H_0: \beta_i = 0$\
$H_a: \beta_i \neq 0$\
$(i = \text{(population, hosp_patients, aged_65_older, new_tests)^2})$

We rejected the Null Hypothesis for the squared term, new_tests, so we can include it in the model. There was an increase of 0.0145 in our Adjusted R Squared, the new value is 0.8822, meaning that we can now explain more of the variation of the dependent variable.

```{r}
model_cases_squared = lm(new_cases ~ population + hosp_patients + aged_65_older +new_tests+ I(new_tests^2)+ I(new_tests^3), data=covid_agg)

summary(model_cases_squared)
```

As the increase in Adjusted R Squared was so little we decided to stop here and use this model as our Best Fit Model.\
$\widehat{y}_{new.cases} = -446.308 + 0.000069x_{population} - 0.366 x_{hosp.patients} +68.194 x_{aged.65.older} + 0.066606x_{new.tests}- 0.0000004 x^2_{new.tests} + 0.000000000001 x^3_{new.tests}$


### New Cases Assumptions 

#### Normality Assumption 

Testing for normality using the Shapiro-Wilk test:

**Null hypothesis:** the sample data are significantly normally distributed

**Alternative hypothesis:** the sample data are not significantly normally distributed

We will set the alpha value to 0.05.

```{r}
shapiro.test(residuals(model_cases_squared))
```


Plotting a Q-Q plot:

```{r}
ggplot(model_cases_squared, aes(sample=model_cases_squared$residuals)) +
stat_qq() +
stat_qq_line()
```

From the output of our test, we get a p-value of 0.4944 which is greater than 0.05. This means we fail to reject our null hypothesis that our sample data is significantly normally distributed and conclude with a significance level of 0.05 that our sample data is not normally distributed. This means that there is no problem with the normality assumption.

#### Homoscedasticity Assumption

Testing for heteroscedasticity using the Breusch-Pagan test:

**Null hypothesis:** heteroscedasticity is not present ($H_0: \sigma^2_1 = \sigma^2_2 =... = \sigma^2_n$)

**Alternative hypothesis:** heteroscedasticity is present ($H_a:$ at least one $\sigma^2_i$ is different from the others)

We will set the alpha value to 0.05.

```{r}
bptest(model_cases_squared)
```

From the output of our test, we get a p-value of 0.3832 which is greater than 0.05. This means we fail to reject the null hypothesis that there is homoscedasticity and conclude with a significance level of 0.05 that our model is not homoscedastic. This means that there is no problem with the homoscedasticity assumption. 

#### Linearity Assumption 

Testing for linearity using a residuals vs predicted $\hat{Y}$ plot:
```{r}
ggplot(model_cases_squared, aes(x=.fitted, y=.resid)) +
geom_point() + geom_smooth()+
geom_hline(yintercept = 0)
```

Looking at the plot above, our model is likely not linear. However, it is not conclusive as just looking at a graph can be subjective.

#### Outliers Assumption

Testing for outliers using leverage:
```{r}
lev=hatvalues(model_cases_squared)
p = length(coef(model_cases_squared))
n = nrow(covid_agg)
outlier3p = lev[lev>(3*p/n)]
outlier3p
```

```{r}
plot(model_cases_squared,which=5)
```

From our output, we have no influential outlier in our data.


#### Independant Errors Assumption

Plotting residuals vs. fitted values to see if the error terms look independant from each other:
```{r}
ggplot(model_cases_squared, aes(x=.fitted, y=.resid)) +
geom_point() + geom_smooth()+
geom_hline(yintercept = 0)
```

Looking at the plot above, it seems that the residuals do not seem to be  evenly distributed, meaning that the residuals are not independent from each other. However, it is not conclusive as just looking at a graph can be subjective.

Since our model passed majority of the assumptions, we will leave the model as is. Therefore, the final model for new_cases is: 
$\widehat{y}_{new.cases} = -446.308 + 0.000069x_{population} - 0.366 x_{hosp.patients} +68.194 x_{aged.65.older} + 0.066606x_{new.tests}- 0.0000004 x^2_{new.tests} + 0.000000000001 x^3_{new.tests}$


### New Deaths Model

For the New Deaths model we followed the same procedure. We started by defining our full model, including all the variables that make senses to predict New Covid-19 Deaths for a specific country. Using the summary() function we are able to see the most important information about our model.

```{r}
model_deaths_full = lm(new_deaths ~ aged_65_older + smokers + cardiovasc_death_rate + diabetes_prevalence + extreme_poverty + gdp_per_capita + median_age + life_expectancy + population + stringency_index + human_development_index + reproduction_rate + hosp_patients + new_tests + population_density, data=covid_agg)

summary(model_deaths_full)
```

Using the *Step Wise Regression Procedure* to create the best fit additive model we found out that only 3 variables were significant; for these 3 terms we can reject reject the Null Hypothesis for the individual coefficient t test, meaning that the terms are significant and the coefficients should be different than 0. The 3 terms that passed the mentioned test are: **population**, **hosp_patients**, **aged_65_older**.

Hypothesis Testing for Individual Coefficient t tests.\
$H_0: \beta_i = 0$\
$H_a: \beta_i \neq 0$\
$(i = \text{population, hosp_patients, aged_65_older})$

```{r}
model_deaths_stepwise = ols_step_both_p(model_deaths_full, pent=0.1, prem=0.3, progress=TRUE)
```

The model obtained after performing the *Step Wise Regression Procedure* is:\
$\widehat{y}_{new.deaths} = -11.0325 + 0.0000016 x_{population} - 0.0075 x_{hosp.patients} + 1.5957 x_{aged.65.older}$

Adjusted R Squared of our model is: 0.7875, meaning that the proportion of the total variation that is explained by the model is 78.75%.

```{r}
model_deaths_revised = lm(new_deaths ~ population + hosp_patients + aged_65_older, data=covid_agg)
summary(model_deaths_revised)
```

Global F-test:

Null hypothesis: $H_{0}: \beta_{population}=\beta_{hosp_patients}=\beta_{life_expectancy}=0$

Alternative hypothesis: At least one $\beta_{i} (i= population, hosp_patients, life_expectancy)$ does not equal 0.

We will set the alpha value to 0.05.
```{r}
model_deaths_null <- lm(new_deaths~1,data=covid_agg)
anova(model_deaths_null,model_deaths_revised)
```

From the output of our global F-test, we get a p-value of 0.00003089  which is less than our alpha value of 0.05 so we can reject our null hypothesis that all of our regression coefficients are equal to 0 and can conclude with a significance level of 0.05 that our model has at least one significant predictor.

Using interactions terms can be a powerful way to increase the efficiency of our model as sometimes the effect of an independent variable on a dependent variable, in our case new Covid-19 deaths, is not constant over all of the values of the other independent variables. As population is on our terms we decided to include interactions terms as depending on the total population of a country all the other variables could change.

Hypothesis Testing for Individual Coefficient t tests.\
$H_0: \beta_i = 0$\
$H_a: \beta_i \neq 0$\
$(i = \text{(population, hosp_patients, aged_65_older)^2})$

We failed to reject our Null Hypothesis for all of the interaction terms, suggesting they should not be included in our model.

```{r}
model_deaths_interactions = lm(new_deaths ~ (population + hosp_patients + aged_65_older)^2, data=covid_agg)
summary(model_deaths_interactions)
```

We would like to try a higher order term to see if we can improve our Adjusted R Squared, as some of the relations with the dependent variable could be curvature instead of linear. To check this relations we will use the ggpairs to plot the correlation between the independent variables and the dependent variables. 

```{r}
covid_higher_order <-data.frame(covid_agg$new_deaths, covid_agg$population, covid_agg$hosp_patients, covid_agg$aged_65_older)

ggpairs(covid_higher_order, lower = list(continuous="smooth_loess", combo="facethist", discrete="facetbar", na="na"))
```

Right away we can observe that there is a curvature relationship between population and new_deaths, for that reason we decided to try a square term to see if the model behaves better. 

Hypothesis Testing for Individual Coefficient t tests.\
$H_0: \beta_i = 0$\
$H_a: \beta_i \neq 0$\
$(i = \text{(population, hosp_patients, aged_65_older)^2})$

We rejected the Null Hypothesis for the squared term, population, so we can include it in the model. There was an increase of 0.0043 in our Adjusted R Squared, the new value is 0.8025, meaning that we can now explain more of the variation of the dependent variable.

```{r}
model_deaths_squared = lm(new_deaths ~ population + hosp_patients + aged_65_older + I(population^2), data=covid_agg)

summary(model_deaths_squared)
```

The addition of a higher order term for population is not significant, so we will not include it. Therefore our final model is: 

$\widehat{y}_{new.deaths} = -11.0325 + 0.0000016 x_{population} - 0.0075 x_{hosp.patients} + 1.5957 x_{aged.65.older}$

### Assumptions for New Deaths Model

#### Normality Assumption 

Testing for normality using the Shapiro-Wilk test:

**Null hypothesis:** the sample data are significantly normally distributed

**Alternative hypothesis:** the sample data are not significantly normally distributed

We will set the alpha value to 0.05.

```{r}
shapiro.test(residuals(model_deaths_revised))
```

Plotting a Q-Q plot:

```{r}
ggplot(model_deaths_revised, aes(sample=model_deaths_revised$residuals)) +
stat_qq() +
stat_qq_line()
```

From the output of our test, we get a p-value of 0.6312 which is greater than 0.05. This means we fail to reject our null hypothesis that our sample data is significantly normally distributed and conclude with a significance level of 0.05 that our sample data is not normally distributed. This means that there is no problem with the normality assumption.

#### Homoscedasticity Assumption 

Testing for heteroscedasticity using the Breusch-Pagan test:

**Null hypothesis:** heteroscedasticity is not present ($H_0: \sigma^2_1 = \sigma^2_2 =... = \sigma^2_n$)

**Alternative hypothesis:** heteroscedasticity is present ($H_a:$ at least one $\sigma^2_i$ is different from the others)

We will set the alpha value to 0.05.

```{r}
bptest(model_deaths_revised)
```

From the output of our test, we get a p-value of 0.07788 which is greater than 0.05. This means we fail to reject the null hypothesis that there is homoscedasticity and conclude with a significance level of 0.05 that our model is homoscedastic. This means that there is no problem with the homoscedasticity assumption. 

#### Linearity Assumption 

Testing for linearity using a residuals vs predicted $\hat{Y}$ plot:
```{r}
ggplot(model_deaths_revised, aes(x=.fitted, y=.resid)) +
geom_point() + geom_smooth()+
geom_hline(yintercept = 0)
```

Looking at the plot above, our model does not seem to be linear.

#### Outliers Assumption

Testing for outliers using leverage:
```{r}
lev=hatvalues(model_deaths_revised)
p = length(coef(model_deaths_revised))
n = nrow(covid_agg)
outlier3p = lev[lev>(3*p/n)]
outlier3p
```

```{r}
plot(model_deaths_revised,which=5)
```

From our output, there seems to be two data points, row 9 and 14 with a leverage greater than $3p/n$. Removing rows with influential outliers:

```{r}
covid_agg2 <- covid_agg[-c(9,14), ]
```


#### Independant Errors Assumption 

Plotting residuals vs. fitted values to see if the error terms look independent from each other:
```{r}
ggplot(model_deaths_revised, aes(x=.fitted, y=.resid)) +
geom_point() + geom_smooth()+
geom_hline(yintercept = 0)
```

Looking at the plot above, it seems that the residuals are not evenly distributed, meaning that the residuals are not independent from each other.

Since our model passed majority of the assumptions, we will leave the model as is. 

```{r}
model_deaths_revised2 <- lm(new_deaths ~ population + hosp_patients + aged_65_older, data=covid_agg2)
summary(model_deaths_revised2)
```

Our final model without any influential outliers is: 
$\widehat{y}_{new.deaths} = 1.2156 + 0.00000094 x_{population} + 0.01379 x_{hosp.patients} - 0.1869 x_{aged.65.older}$

This model gives us an adjusted R-squared value of 0.9225. Which means out model explains 92.25% of the variance in new_deaths. This is an increase of 0.135 from our model with the influential outliers. 


\newpage
# Results



\newpage
# Discussion



\newpage
# References
Klobucista, Claire (2021, May 10). By How Much Are Countries Underreporting COVID-19 Cases and Deaths?. Council of Foreign Relations. https://www.cfr.org/in-brief/how-much-are-countries-underreporting-covid-19-cases-and-deaths


